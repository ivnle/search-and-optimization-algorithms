# Search and Optimization Algorithms
Implementations and visualizations of core search and optimization algorithms.

## Gradient Descent 
Given a once differentiable function, gradient descent gives us a way to identify a local minimum of the function.

![](figures/grad_desc.png)

## Newton Descent
Given a twice differentiable function, newton descent gives us a way to identify the 

![](figures/newton.png)

## Conjugate Descent
![](figures/conj_desc.png)

## Simulated Annealing
![](figures/sim_ann.png)

## Cross-Entropy Methods
![](figures/cross_ent.png)

## Search Gradient
![](figures/search_grad.png)

## A* search
The darker cells are obstacles that our agent cannot pass through. The yellow and green cells represent the goal and start nodes respectively. The goal is to move from the start node to the goal node in the fewest number of steps.

![](figures/a_star_maze.png)
![](figures/a_star_path.png)

## minimax search
TODO

## (extra) RRT (rapidly-exploring random trees)
TODO

## Value iteration
![](figures/val_it.png)

## Policy iteration
![](figures/policy_it.png)

## Monte Carlo Policy Evaluation 
![](figures/monte_carlo_eval.png)

## Temporal Difference Policy Evaluation

![](figures/temp_diff.png)

## Tabular Q learning

![](figures/tab_q_learning.png)

## Deep Q learning
TODO

## (extra) PPO (Proximal Policy Optimization)
TODO

## Monte Carlo Tree Search
TODO